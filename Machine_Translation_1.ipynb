{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m64VxDTW5euL"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rimgsXgj5eqJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=[[[1,2,3,4],\n",
        " [5,6,7,8]]]\n",
        "tf.argmax(a,axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0FW_3vCrxy7",
        "outputId": "ec36db4c-7eb5-489c-a8fc-1f30fd10d1d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 2), dtype=int64, numpy=array([[3, 3]])>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51EYLmTZ5eor"
      },
      "source": [
        "## Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9hHRAbj3oxf",
        "outputId": "7cb2192d-96e8-40a3-f86d-addca8e93ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-25 05:03:33--  https://www.manythings.org/anki/fra-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7420323 (7.1M) [application/zip]\n",
            "Saving to: ‘fra-eng.zip’\n",
            "\n",
            "fra-eng.zip         100%[===================>]   7.08M  4.19MB/s    in 1.7s    \n",
            "\n",
            "2023-06-25 05:03:35 (4.19 MB/s) - ‘fra-eng.zip’ saved [7420323/7420323]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.manythings.org/anki/fra-eng.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5CsfeTM4ww0",
        "outputId": "f8a80ea7-8c86-4f97-98fc-8ddd4a86f2c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fra-eng.zip\n",
            "  inflating: /content/fra/_about.txt  \n",
            "  inflating: /content/fra/fra.txt    \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/fra-eng.zip\" -d \"/content/fra\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6viu4go75QBa"
      },
      "outputs": [],
      "source": [
        "dataset=tf.data.TextLineDataset(\"/content/fra/fra.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1W8YYep6QA2",
        "outputId": "51381ac0-89e3-47a0-b3eb-66595c74db62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tMarche.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8090732 (Micsmithel)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tEn route !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8267435 (felix63)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Go.\\tBouge !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #9022935 (Micsmithel)', shape=(), dtype=string)\n",
            "tf.Tensor(b'Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)', shape=(), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.take(5):\n",
        "  print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a6eX1fY7seQ",
        "outputId": "aa009d41-d7b0-45d3-8951-87f950fd0be3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "217975"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "len(list(dataset))# total number of lines/documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goCJ3H226UPq",
        "outputId": "f14127e6-5fd1-433c-cc37-19bd1530d1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b\"It may be impossible to get a completely error-free corpus due to the nature of this kind of collaborative effort. However, if we encourage members to contribute sentences in their own languages rather than experiment in languages they are learning, we might be able to minimize errors.\\tIl est peut-\\xc3\\xaatre impossible d'obtenir un Corpus compl\\xc3\\xa8tement d\\xc3\\xa9nu\\xc3\\xa9 de fautes, \\xc3\\xa9tant donn\\xc3\\xa9e la nature de ce type d'entreprise collaborative. Cependant, si nous encourageons les membres \\xc3\\xa0 produire des phrases dans leurs propres langues plut\\xc3\\xb4t que d'exp\\xc3\\xa9rimenter dans les langues qu'ils apprennent, nous pourrions \\xc3\\xaatre en mesure de r\\xc3\\xa9duire les erreurs.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2024159 (CK) & #2024564 (sacredceltic)\", shape=(), dtype=string)\n",
            "106\n"
          ]
        }
      ],
      "source": [
        "for i in dataset.skip(217974).take(1):\n",
        "  print(i)\n",
        "  print(len(tf.strings.split(i,\" \"))) # len of last line/document to get the sequence length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5JEZ5Sv48sm"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM66pT2S5AVY"
      },
      "source": [
        "### Converting text to vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Fma3J3LA6-lP"
      },
      "outputs": [],
      "source": [
        "# Vectorizing english sequence - token index method\n",
        "english_Vector=tf.keras.layers.TextVectorization(max_tokens=10000,\n",
        "                                                 standardize=\"lower_and_strip_punctuation\",\n",
        "                                                 output_sequence_length=70\n",
        "                                                 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OiH6Iy7yCWUc"
      },
      "outputs": [],
      "source": [
        "# Vectorizing french sequence - token index method\n",
        "french_Vector=tf.keras.layers.TextVectorization(max_tokens=10000,\n",
        "                                                 standardize=\"lower_and_strip_punctuation\",\n",
        "                                                 output_sequence_length=70\n",
        "                                                 )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MQ4kikyCZES"
      },
      "source": [
        "### Getting Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "e0ol5-OVAtEx"
      },
      "outputs": [],
      "source": [
        "#for getting all vocabulary\n",
        "def vocab(inp):\n",
        "  text=tf.strings.split(inp,\"\\t\")\n",
        "  return text[0],\"start \"+text[1]+\" end\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "42oslPXGBgn2"
      },
      "outputs": [],
      "source": [
        "vocab_text=dataset.map(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "33RTJyYTB2J0"
      },
      "outputs": [],
      "source": [
        "english=vocab_text.map(lambda x,y:x)\n",
        "french=vocab_text.map(lambda x,y:y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3-GEf2Aa7OFf"
      },
      "outputs": [],
      "source": [
        "#getting vocabulary for vector layer\n",
        "english_Vector.adapt(english)\n",
        "french_Vector.adapt(french)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vectorizing"
      ],
      "metadata": {
        "id": "2NXKx8dZHPms"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bTA8WzMa5d4l"
      },
      "outputs": [],
      "source": [
        "# model should have one input for encoder (english), one input for decoder (french shifted right), one output for decoder (french w/ end token)\n",
        "def in_out(text):\n",
        "  split=tf.strings.split(text, \"\\t\")\n",
        "  return split[0],\"start \"+split[1],split[1]+\" end\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_out=dataset.map(in_out)"
      ],
      "metadata": {
        "id": "bR79aIa9Gr4q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FNCO5BTW5d1q"
      },
      "outputs": [],
      "source": [
        "def vectorizer(inp_enc,inp_dec,out_dec):\n",
        "  return english_Vector(inp_enc),french_Vector(inp_dec),french_Vector(out_dec)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=inp_out.map(vectorizer)"
      ],
      "metadata": {
        "id": "Qqcn3PN9G01c"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j,k in data.take(1):\n",
        "  print(i,j,k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU2OHFrnHNtr",
        "outputId": "370bcb6b-0d3f-4fc3-aee7-6034abe282f2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[44  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0], shape=(70,), dtype=int64) tf.Tensor(\n",
            "[  2 104   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(70,), dtype=int64) tf.Tensor(\n",
            "[104   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0], shape=(70,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_Vector.get_vocabulary()[44]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5M_RZjhcHghh",
        "outputId": "31c04f80-0da4-4fdb-b822-3669dc75c75a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "french_Vector.get_vocabulary()[104]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "H-k5Ax0bHmMP",
        "outputId": "585c0b0a-3fe3-41e1-eb84-ff61f7194f60"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'va'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation for model\n",
        "def vectorizer_model(inp_enc,inp_dec,out_dec):\n",
        "  return (english_Vector(inp_enc),french_Vector(inp_dec)),french_Vector(out_dec)"
      ],
      "metadata": {
        "id": "qwzMevkEQs51"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "required_data=inp_out.map(vectorizer_model)"
      ],
      "metadata": {
        "id": "l5CWzULfQ4OE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in required_data.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzx4sYMqYYh0",
        "outputId": "ac136116-54b2-464e-88bd-293c0972f920"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(70,), dtype=int64, numpy=\n",
            "array([44,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "        0,  0])>, <tf.Tensor: shape=(70,), dtype=int64, numpy=\n",
            "array([  2, 104,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req_data_1=required_data.shuffle(buffer_size=3000).batch(64).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "number_of_batches=217975/64\n",
        "training_data_1=req_data_1.take(int(0.8*number_of_batches))\n",
        "val_data_buf=req_data_1.skip(int(0.8*number_of_batches))\n",
        "val_data_1=val_data_buf.take(int(0.1*number_of_batches))\n",
        "test_data_1=val_data_1.skip(int(0.1*number_of_batches))"
      ],
      "metadata": {
        "id": "ZRxIWMPFYr-P"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in training_data_1.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UE5fc4YgY8x0",
        "outputId": "83bb89e1-58f1-4602-d1dd-37b5f227a68f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(64, 70), dtype=int64, numpy=\n",
            "array([[  21,  487,    0, ...,    0,    0,    0],\n",
            "       [1099,    0,    0, ...,    0,    0,    0],\n",
            "       [   2,  141,   58, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2,   38,  490, ...,    0,    0,    0],\n",
            "       [  35,   26,   44, ...,    0,    0,    0],\n",
            "       [ 460,  164,    0, ...,    0,    0,    0]])>, <tf.Tensor: shape=(64, 70), dtype=int64, numpy=\n",
            "array([[   2,    4,   25, ...,    0,    0,    0],\n",
            "       [   2,    1,    0, ...,    0,    0,    0],\n",
            "       [   2, 6795,  118, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [   2,    4,  387, ...,    0,    0,    0],\n",
            "       [   2,  937,  214, ...,    0,    0,    0],\n",
            "       [   2, 2728,    0, ...,    0,    0,    0]])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "req_data=required_data.shuffle(buffer_size=3000).unbatch().batch(64).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "mpCT97p6dIgg"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in req_data.take(1):\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFY6N6O6dSKR",
        "outputId": "01609447-d54a-4800-f08f-c1487ccb7e0a"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([434,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>, <tf.Tensor: shape=(64,), dtype=int64, numpy=\n",
            "array([  2, 811,  34,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
            "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0])>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byM_kOpq5dzF"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "K-6wdgmfCom6"
      },
      "outputs": [],
      "source": [
        "# encoder\n",
        "input_1=tf.keras.layers.Input(shape=(70))\n",
        "embedding=tf.keras.layers.Embedding(10000,(50))(input_1)\n",
        "encoded_output=tf.keras.layers.Bidirectional(tf.keras.layers.GRU(300))(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "Y9R-Rd6U9BVS"
      },
      "outputs": [],
      "source": [
        "# decoder\n",
        "input_dec=tf.keras.layers.Input(shape=(70,))\n",
        "embedding_dec=tf.keras.layers.Embedding(10000,50)(input_dec)\n",
        "decoded_output=tf.keras.layers.GRU(600,return_sequences=True)(embedding_dec,initial_state=encoded_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "qbaKhd1J9BRu"
      },
      "outputs": [],
      "source": [
        "# fully connected\n",
        "dp=tf.keras.layers.Dropout(0.5)(decoded_output)\n",
        "fc=tf.keras.layers.Dense(10000,activation=\"softmax\")(dp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "QC94yxe19BQF"
      },
      "outputs": [],
      "source": [
        "# Translation\n",
        "translation=tf.keras.Model([input_1,input_dec],fc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtIjZYBrOpym",
        "outputId": "312fb52f-6883-4014-fce1-8624d367fafa"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_8 (InputLayer)           [(None, 70)]         0           []                               \n",
            "                                                                                                  \n",
            " input_9 (InputLayer)           [(None, 70)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)        (None, 70, 50)       500000      ['input_8[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_8 (Embedding)        (None, 70, 50)       500000      ['input_9[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirectional  (None, 600)         633600      ['embedding_7[0][0]']            \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " gru_7 (GRU)                    (None, 70, 600)      1173600     ['embedding_8[0][0]',            \n",
            "                                                                  'bidirectional_3[0][0]']        \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 70, 600)      0           ['gru_7[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 70, 10000)    6010000     ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 8,817,200\n",
            "Trainable params: 8,817,200\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(5e-4),metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "RMxEd1InOryJ"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation.fit(training_data_1,validation_data=val_data_1,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZijU66pP_Ab",
        "outputId": "e903363f-0c7b-4991-8602-1d7dbf0f667a"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2724/2724 [==============================] - 393s 141ms/step - loss: 0.2715 - accuracy: 0.9551 - val_loss: 0.3653 - val_accuracy: 0.9306\n",
            "Epoch 2/10\n",
            "2724/2724 [==============================] - 335s 123ms/step - loss: 0.1702 - accuracy: 0.9638 - val_loss: 0.3319 - val_accuracy: 0.9344\n",
            "Epoch 3/10\n",
            "2724/2724 [==============================] - 333s 122ms/step - loss: 0.1459 - accuracy: 0.9669 - val_loss: 0.3181 - val_accuracy: 0.9364\n",
            "Epoch 4/10\n",
            "2724/2724 [==============================] - 334s 122ms/step - loss: 0.1317 - accuracy: 0.9689 - val_loss: 0.3034 - val_accuracy: 0.9385\n",
            "Epoch 5/10\n",
            "2724/2724 [==============================] - 334s 122ms/step - loss: 0.1217 - accuracy: 0.9704 - val_loss: 0.2980 - val_accuracy: 0.9395\n",
            "Epoch 6/10\n",
            "2724/2724 [==============================] - 334s 122ms/step - loss: 0.1140 - accuracy: 0.9717 - val_loss: 0.2942 - val_accuracy: 0.9402\n",
            "Epoch 7/10\n",
            "2724/2724 [==============================] - 335s 123ms/step - loss: 0.1078 - accuracy: 0.9728 - val_loss: 0.2942 - val_accuracy: 0.9405\n",
            "Epoch 8/10\n",
            "2724/2724 [==============================] - 335s 123ms/step - loss: 0.1027 - accuracy: 0.9737 - val_loss: 0.2933 - val_accuracy: 0.9409\n",
            "Epoch 9/10\n",
            "2724/2724 [==============================] - 333s 122ms/step - loss: 0.0984 - accuracy: 0.9745 - val_loss: 0.2925 - val_accuracy: 0.9413\n",
            "Epoch 10/10\n",
            "2724/2724 [==============================] - 332s 122ms/step - loss: 0.0946 - accuracy: 0.9752 - val_loss: 0.2919 - val_accuracy: 0.9415\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f27fd304370>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word={x:y for x, y in zip(range(len(french_Vector.get_vocabulary())),\n",
        "                                   french_Vector.get_vocabulary())}"
      ],
      "metadata": {
        "id": "IKFah1toudpl"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translator(english_sent):\n",
        "  eng_vector=english_Vector([english_sent])\n",
        "\n",
        "  dec_inp=\"start\"\n",
        "  for i in range(70):\n",
        "    fre_vector=french_Vector([dec_inp])\n",
        "    output=translation.predict([eng_vector,fre_vector])\n",
        "\n",
        "    word=tf.argmax(output,axis=-1)[0][i].numpy()\n",
        "    french_word=index_to_word[word]\n",
        "\n",
        "    if french_word==\"end\":\n",
        "      break\n",
        "    dec_inp+=' '+french_word\n",
        "  return dec_inp"
      ],
      "metadata": {
        "id": "_JeFOa2AP-9g"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator(\"i see.\")"
      ],
      "metadata": {
        "id": "TZZkjZZyo4f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "85b596a7-15a9-469f-9397-4d6995c4df47"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'start je vois'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator(\" i go there\")"
      ],
      "metadata": {
        "id": "wzbhKUd8eF9T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9092473e-53f2-4bf4-f1af-9b80bb2bb1f4"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'start jy suggère'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translator(\"where are you\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "5_apQLa8Ydrx",
        "outputId": "13d514e9-ba4a-46d8-f0fe-61b61e3fd70d"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'start où vous [UNK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QveKTSD2tc-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}